{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP for ML Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis**: Part of Speech (POS) tagging and syntactic dependency parsing provides valuable information for classifying imperative phrases. The thinking is that being able to detect imperative phrases will transfer well to detecting tasks and to-dos.\n",
    "\n",
    "#### Some Terminology\n",
    "- [_Imperative mood_](https://en.wikipedia.org/wiki/Imperative_mood) is \"used principally for ordering, requesting or advising the listener to do (or not to do) something... also often used for giving instructions as to how to perform a task.\"\n",
    "- _Part of speech (POS)_ is a way of categorizing a word based on its syntactic function.\n",
    "    - The POS tagger from Spacy.io that is used in this notebook differentiates between [*pos_* and *tag_*](https://spacy.io/docs/api/annotation#pos-tagging-english) - *POS (pos_)* refers to \"coarse-grained part-of-speech\" like `VERB`, `ADJ`, or `PUNCT`; and *POSTAG (tag_)* refers to \"fine-grained part-of-speech\" like `VB`, `JJ`, or `.`.\n",
    "- _Syntactic dependency parsing_ is a way of connecting words based on syntactic relationships, [such as](https://spacy.io/docs/api/annotation#dependency-parsing-english) `DOBJ` (direct object), `PREP` (prepositional modifier), or `POBJ` (object of preposition).\n",
    "    - Check out the dependency parse for the phrase [\"Send the report by Kyle by tomorrow\"](https://demos.explosion.ai/displacy/?text=Send%20the%20report%20by%20Kyle%20by%20tomorrow&model=en&cpu=1&cph=1) as an example\n",
    "\n",
    "#### Features\n",
    "The imperative mood centers around _actions_, and actions are generally represented in English using verbs. So the features are engineered to also center on the VERB:\n",
    "1. *FeatureName.VERB*: Does the phrase contain VERB(s) of the tag form VB*?\n",
    "2. *FeatureName.FOLLOWING_POS*: Are the words following the VERB(s) of certain parts of speech?\n",
    "3. *FeatureName.FOLLOWING_POSTAG*: Are the words following the VERB(s) of certain POS tags?\n",
    "4. *FeatureName.CHILD_DEP*: Are the VERB(s) parents of certain syntactic dependencies?\n",
    "5. *FeatureName.PARENT_DEP*: Are the VERB(s) children of certain syntactic dependencies?\n",
    "6. *FeatureName.CHILD_POS*: Are the syntactic dependencies that the VERB(s) are children of of certain parts of speech?\n",
    "7. *FeatureName.CHILD_POSTAG*: Are the syntactic dependencies that the VERB(s) are children of of certain POS tags?\n",
    "8. *FeatureName.PARENT_POS*: Are the syntactic dependencies that the VERB(s) parent of certain parts of speech?\n",
    "9. *FeatureName.PARENT_POSTAG*: Are the syntactic dependencies that the VERB(s) parent of certain POS tags?\n",
    "\n",
    "Note that features 2-9 all depend on feature 1 between `True`; if `False`, phrase vectorization will result in all zeroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a recipe corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote and ran `epicurious_recipes.py`\\* to scrape Epicurious.com for recipe instructions and descriptions. Output is `epicurious-pos.txt` and `epicurious-neg.txt`.\n",
    "\n",
    "\\* _script loosely based off of https://github.com/benosment/hrecipe-parse_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that deriving all negative examples in the training set from Epicurious recipe descriptions would result in negative examples that are longer and syntactically more complicated than the positive examples. This is a form of bias.\n",
    "\n",
    "To (hopefully?) correct for this a bit, I will add the short movie reviews found at https://pythonprogramming.net/static/downloads/short_reviews/ as more negative examples.\n",
    "\n",
    "This still feels weird because we're selecting negative examples only from specific categories of text (recipe descriptions, short movie reviews) - just because they're readily available.\n",
    "\n",
    "Ultimately though, this recipe corpus is a **stopgap/proof of concept** for a corpus more relevant to tasks later on, so I won't worry further about this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "pos_data_path = BASE_DIR + '/pos.txt'\n",
    "neg_data_path = BASE_DIR + '/neg.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pos_data_path, 'r', encoding='utf-8') as f:\n",
    "    pos_data = f.read()\n",
    "with open(neg_data_path, 'r', encoding='utf-8') as f:\n",
    "    neg_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_data_split = pos_data.split('\\n')\n",
    "neg_data_split = neg_data.split('\\n')\n",
    "\n",
    "num_pos = len(pos_data_split)\n",
    "num_neg = len(neg_data_split)\n",
    "\n",
    "# 50/50 split between the number of positive and negative samples\n",
    "num = num_pos if num_pos > num_neg else num_neg\n",
    "\n",
    "# shuffle samples\n",
    "random.shuffle(pos_data_split)\n",
    "random.shuffle(neg_data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "for l in pos_data_split[:num]:\n",
    "    lines.append((l, 'pos'))\n",
    "for l in neg_data_split[:num]:\n",
    "    lines.append((l, 'neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "class FeatureName(Enum):\n",
    "    VERB = auto()\n",
    "    FOLLOWING_POS = auto()\n",
    "    FOLLOWING_POSTAG = auto()\n",
    "    CHILD_DEP = auto()\n",
    "    PARENT_DEP = auto()\n",
    "    CHILD_POS = auto()\n",
    "    CHILD_POSTAG = auto()\n",
    "    PARENT_POS = auto()\n",
    "    PARENT_POSTAG = auto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [spaCy.io](https://spacy.io/) for NLP\n",
    "_Because Stanford CoreNLP is hard to install for Python_\n",
    "\n",
    "Found Spacy through an article on [\"Training a Classifier for Relation Extraction from Medical Literature\"](https://www.microsoft.com/developerblog/2016/09/13/training-a-classifier-for-relation-extraction-from-medical-literature/) ([GitHub](https://github.com/CatalystCode/corpus-to-graph-ml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"nltk_library_comparison.png\" alt=\"NLTK library comparison chart https://spacy.io/docs/api/#comparison\" style=\"width: 400px; margin: 0;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!conda config --add channels conda-forge\n",
    "#!conda install spacy\n",
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Spacy Data Model for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy's sentence segmentation is lacking... https://github.com/explosion/spaCy/issues/235. So each '\\n' will start a new Spacy Doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spacy_docs(ll):\n",
    "    dd = [(nlp(l[0]), l[1]) for l in ll]\n",
    "    # collapse noun phrases into single compounds\n",
    "    for d in dd:\n",
    "        for np in d[0].noun_chunks:\n",
    "            np.merge(np.root.tag_, np.text, np.root.ent_type_)\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = create_spacy_docs(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization, POS tagging, and dependency parsing happened automatically with the `nlp(line)` calls above! So let's look at the outputs.\n",
    "\n",
    "https://spacy.io/docs/usage/data-model and https://spacy.io/docs/api/doc will be useful going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The extraction process can be tricky.]\n",
      "[Reduce the speed to low, gradually add the confectioners’ sugar, and beat until incorporated.]\n",
      "[Slice into 1/4\" wedges.]\n",
      "[Serve with sour cream alongside.]\n",
      "[Dollop cornbread batter over meat mixture, then smooth into an even layer.]\n",
      "[Using a mixer is]\n",
      "[Cookies can be baked 1 week ahead; transfer to a resealable plastic bag and freeze.]\n",
      "[You should end up with 30 cookies total.]\n",
      "[Add the spinach and VegiZest or other no-salt seasoning blend, and cook until spinach is wilted.]\n",
      "[Transfer cutlets to a platter.]\n"
     ]
    }
   ],
   "source": [
    "for doc in docs[:10]:\n",
    "    print(list(doc[0].sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The extraction process]\n",
      "[the speed, the confectioners’ sugar]\n",
      "[Slice]\n",
      "[sour cream]\n",
      "[batter, meat mixture, an even layer]\n",
      "[a mixer]\n",
      "[Cookies, a resealable plastic bag, freeze]\n",
      "[You, 30 cookies]\n",
      "[the spinach, VegiZest, other no-salt seasoning blend, spinach]\n",
      "[Transfer, a platter]\n"
     ]
    }
   ],
   "source": [
    "for doc in docs[:10]:\n",
    "    print(list(doc[0].noun_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Spacy's dependency graph visualization](https://demos.explosion.ai/displacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extraction process nsubj The extraction process NOUN NN be []\n",
      "can aux can VERB MD be []\n",
      "be ROOT be VERB VB be [The extraction process, can, tricky, .]\n",
      "tricky acomp tricky ADJ JJ be []\n",
      ". punct . PUNCT . be []\n",
      "Reduce ROOT reduce VERB VB Reduce [the speed, add, .]\n",
      "the speed dobj the speed NOUN NN Reduce [low, ,]\n",
      "to aux to PART TO low []\n",
      "low relcl low VERB VB the speed [to]\n",
      ", punct , PUNCT , the speed []\n",
      "gradually advmod gradually ADV RB add []\n",
      "add conj add VERB VB Reduce [gradually, the confectioners’ sugar, and, beat]\n",
      "the confectioners’ sugar dobj the confectioners’ sugar NOUN NN add [,]\n",
      ", punct , PUNCT , the confectioners’ sugar []\n",
      "and cc and CCONJ CC add []\n",
      "beat conj beat VERB VB add [incorporated]\n",
      "until mark until ADP IN incorporated []\n",
      "incorporated advcl incorporate VERB VBN beat [until]\n",
      ". punct . PUNCT . Reduce []\n",
      "Slice nsubj Slice PROPN NNP wedges [1/4]\n",
      "into quantmod into ADP IN 1/4 []\n",
      "1/4 nummod 1/4 NUM CD Slice [into, \"]\n",
      "\" punct \" PUNCT '' 1/4 []\n",
      "wedges ROOT wedge NOUN NNS wedges [Slice, .]\n",
      ". punct . PUNCT . wedges []\n",
      "Serve ROOT serve VERB VB Serve [with, .]\n",
      "with prep with ADP IN Serve [sour cream]\n",
      "sour cream pobj sour cream NOUN NN with [alongside]\n",
      "alongside prep alongside ADV RB sour cream []\n",
      ". punct . PUNCT . Serve []\n",
      "Dollop compound dollop PROPN NNP cornbread []\n",
      "cornbread ROOT cornbread VERB VBZ cornbread [Dollop, batter, ,, smooth, .]\n",
      "batter dobj batter NOUN NN cornbread [over]\n",
      "over prep over ADP IN batter [meat mixture]\n",
      "meat mixture pobj meat mixture NOUN NN over []\n",
      ", punct , PUNCT , cornbread []\n",
      "then advmod then ADV RB smooth []\n",
      "smooth conj smooth VERB VB cornbread [then, into]\n",
      "into prep into ADP IN smooth [an even layer]\n",
      "an even layer pobj an even layer NOUN NN into []\n",
      ". punct . PUNCT . cornbread []\n"
     ]
    }
   ],
   "source": [
    "for doc in docs[:5]:\n",
    "    for token in doc[0]:\n",
    "        print(token.text, token.dep_, token.lemma_, token.pos_, token.tag_, token.head, list(token.children))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def featurize(d):\n",
    "    s_features = defaultdict(int)\n",
    "    for idx, token in enumerate(d):\n",
    "        #print(token, token.pos_, token.tag_)\n",
    "        if re.match(r'VB.?', token.tag_) is not None: # note: not using token.pos == VERB because this also includes BES, HVS, MD tags \n",
    "            s_features[FeatureName.VERB.name] += 1\n",
    "            # FOLLOWING_POS\n",
    "            next_idx = idx + 1;\n",
    "            if next_idx < len(d):\n",
    "                s_features[f'{FeatureName.FOLLOWING_POS.name}_{d[next_idx].pos_}'] += 1\n",
    "                s_features[f'{FeatureName.FOLLOWING_POSTAG.name}_{d[next_idx].tag_}'] += 1\n",
    "            # VERB_HEAD_DEP\n",
    "            # VERB_HEAD_POS\n",
    "            '''\n",
    "            \"Because the syntactic relations form a tree, every word has exactly one head.\n",
    "            You can therefore iterate over the arcs in the tree by iterating over the words in the sentence.\"\n",
    "            https://spacy.io/docs/usage/dependency-parse#navigating\n",
    "            '''\n",
    "            if (token.head is not token):\n",
    "                s_features[f'{FeatureName.PARENT_DEP.name}_{token.head.dep_.upper()}'] += 1\n",
    "                s_features[f'{FeatureName.PARENT_POS.name}_{token.head.pos_}'] += 1\n",
    "                s_features[f'{FeatureName.PARENT_POSTAG.name}_{token.head.tag_}'] += 1\n",
    "            # VERB_CHILD_DEP\n",
    "            # VERB_CHILD_POS\n",
    "            for child in token.children:\n",
    "                s_features[f'{FeatureName.CHILD_DEP.name}_{child.dep_.upper()}'] += 1\n",
    "                s_features[f'{FeatureName.CHILD_POS.name}_{child.pos_}'] += 1\n",
    "                s_features[f'{FeatureName.CHILD_POSTAG.name}_{child.tag_}'] += 1\n",
    "    return dict(s_features)\n",
    "        #print(dict(s_features))\n",
    "    #print()\n",
    "\n",
    "#print(featuresets, len(featuresets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(featurize(doc[0]), doc[1]) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats on feature set lengths:\n",
      "mean: 24.826197414630503\n",
      "stdev: 14.872887747698636\n",
      "median: 25\n",
      "mode: 0\n",
      "max: 75\n",
      "min: 0\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, median, mode, stdev\n",
    "f_lengths = [len(fs[0]) for fs in featuresets]\n",
    "\n",
    "print('Stats on feature set lengths:')\n",
    "print(f'mean: {mean(f_lengths)}')\n",
    "print(f'stdev: {stdev(f_lengths)}')\n",
    "print(f'median: {median(f_lengths)}')\n",
    "print(f'mode: {mode(f_lengths)}')\n",
    "print(f'max: {max(f_lengths)}')\n",
    "print(f'min: {min(f_lengths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'CHILD_DEP_ACOMP': 1,\n",
       "   'CHILD_DEP_AUX': 1,\n",
       "   'CHILD_DEP_NSUBJ': 1,\n",
       "   'CHILD_DEP_PUNCT': 1,\n",
       "   'CHILD_POSTAG_.': 1,\n",
       "   'CHILD_POSTAG_JJ': 1,\n",
       "   'CHILD_POSTAG_MD': 1,\n",
       "   'CHILD_POSTAG_NN': 1,\n",
       "   'CHILD_POS_ADJ': 1,\n",
       "   'CHILD_POS_NOUN': 1,\n",
       "   'CHILD_POS_PUNCT': 1,\n",
       "   'CHILD_POS_VERB': 1,\n",
       "   'FOLLOWING_POSTAG_JJ': 1,\n",
       "   'FOLLOWING_POS_ADJ': 1,\n",
       "   'VERB': 1},\n",
       "  'pos'),\n",
       " ({'CHILD_DEP_ADVCL': 1,\n",
       "   'CHILD_DEP_ADVMOD': 1,\n",
       "   'CHILD_DEP_AUX': 1,\n",
       "   'CHILD_DEP_CC': 1,\n",
       "   'CHILD_DEP_CONJ': 2,\n",
       "   'CHILD_DEP_DOBJ': 2,\n",
       "   'CHILD_DEP_MARK': 1,\n",
       "   'CHILD_DEP_PUNCT': 1,\n",
       "   'CHILD_POSTAG_.': 1,\n",
       "   'CHILD_POSTAG_CC': 1,\n",
       "   'CHILD_POSTAG_IN': 1,\n",
       "   'CHILD_POSTAG_NN': 2,\n",
       "   'CHILD_POSTAG_RB': 1,\n",
       "   'CHILD_POSTAG_TO': 1,\n",
       "   'CHILD_POSTAG_VB': 2,\n",
       "   'CHILD_POSTAG_VBN': 1,\n",
       "   'CHILD_POS_ADP': 1,\n",
       "   'CHILD_POS_ADV': 1,\n",
       "   'CHILD_POS_CCONJ': 1,\n",
       "   'CHILD_POS_NOUN': 2,\n",
       "   'CHILD_POS_PART': 1,\n",
       "   'CHILD_POS_PUNCT': 1,\n",
       "   'CHILD_POS_VERB': 3,\n",
       "   'FOLLOWING_POSTAG_,': 1,\n",
       "   'FOLLOWING_POSTAG_.': 1,\n",
       "   'FOLLOWING_POSTAG_IN': 1,\n",
       "   'FOLLOWING_POSTAG_NN': 2,\n",
       "   'FOLLOWING_POS_ADP': 1,\n",
       "   'FOLLOWING_POS_NOUN': 2,\n",
       "   'FOLLOWING_POS_PUNCT': 2,\n",
       "   'PARENT_DEP_CONJ': 2,\n",
       "   'PARENT_DEP_DOBJ': 1,\n",
       "   'PARENT_DEP_ROOT': 1,\n",
       "   'PARENT_POSTAG_NN': 1,\n",
       "   'PARENT_POSTAG_VB': 3,\n",
       "   'PARENT_POS_NOUN': 1,\n",
       "   'PARENT_POS_VERB': 3,\n",
       "   'VERB': 5},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(featuresets)\n",
    "\n",
    "split_num = round(num / 5)\n",
    "\n",
    "# train and test sets\n",
    "testing_set = featuresets[:split_num]\n",
    "training_set =  featuresets[split_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decoupling the functionality of nltk.classify.accuracy\n",
    "def predict(classifier, gold):\n",
    "    predictions = classifier.classify_many([fs for (fs, l) in gold])\n",
    "    return list(zip([l for (fs, l) in gold], predictions))\n",
    "\n",
    "def accuracy(predict):\n",
    "    correct = [label == prediction for (label, prediction) in predict]\n",
    "    if correct:\n",
    "        return sum(correct) / len(correct)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes classifier accuracy percent: 84.67087466185752\n",
      "MultinomialNB classifier accuracy percent: 87.10550045085664\n",
      "BernoulliNB classifier accuracy percent: 75.87917042380523\n",
      "LogisticRegression classifier accuracy percent: 89.9458972046889\n",
      "SGDClassifier classifier accuracy percent: 87.60144274120829\n",
      "SVC classifier accuracy percent: 87.91704238052299\n",
      "LinearSVC classifier accuracy percent: 89.404869251578\n"
     ]
    }
   ],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify.decisiontree import DecisionTreeClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "nb = NaiveBayesClassifier.train(training_set)\n",
    "nb_predict = predict(nb, testing_set)\n",
    "nb_accuracy = accuracy(nb_predict)\n",
    "print(\"NaiveBayes classifier accuracy percent:\", (nb_accuracy*100))\n",
    "\n",
    "mnb = SklearnClassifier(MultinomialNB())\n",
    "mnb.train(training_set)\n",
    "mnb_predict = predict(mnb, testing_set)\n",
    "mnb_accuracy = accuracy(mnb_predict)\n",
    "print(\"MultinomialNB classifier accuracy percent:\", (mnb_accuracy*100))\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB classifier accuracy percent:\", (classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression classifier accuracy percent:\", (classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier classifier accuracy percent:\", (classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(training_set)\n",
    "print(\"SVC classifier accuracy percent:\", (classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC classifier accuracy percent:\", (classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "# slow\n",
    "#DT_classifier = DecisionTreeClassifier.train(training_set)\n",
    "#print(\"DecisionTree classifier accuracy percent:\", (classify.accuracy(DT_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC: ['neg', 'neg', 'pos', 'neg', 'pos', 'neg', 'neg']\n",
      "LogisticRegression: ['neg', 'neg', 'pos', 'neg', 'pos', 'neg', 'neg']\n",
      "SGD: ['neg', 'neg', 'pos', 'neg', 'pos', 'neg', 'neg']\n"
     ]
    }
   ],
   "source": [
    "phrases = [\"Mow lawn\", \"Mow the lawn\", \"Buy new shoes\", \"Feed the dog\", \"Send report to Kyle\", \"Send the report to Kyle\", \"Peel the potatoes\"]\n",
    "features = [featurize(nlp(phrase)) for phrase in phrases]\n",
    "\n",
    "predict_linearSVC = LinearSVC_classifier.classify_many(features)\n",
    "predict_logistic = LogisticRegression_classifier.classify_many(features)\n",
    "predict_SGD = SGDClassifier_classifier.classify_many(features)\n",
    "\n",
    "print(f'LinearSVC: {predict_linearSVC}')\n",
    "print(f'LogisticRegression: {predict_logistic}')\n",
    "print(f'SGD: {predict_SGD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the highest performing classifiers (`LogisticRegression, LinearSVC: 88.89`) are producing quite different results on our sample task list:\n",
    "    - \"Mow lawn\"\n",
    "        - LinearSVC: neg\n",
    "        - LogisticRegression: neg\n",
    "    - \"Mow the lawn\"\n",
    "        - LinearSVC: pos\n",
    "        - LogisticRegression: neg\n",
    "    - \"Buy new shoes\"\n",
    "        - LinearSVC: pos\n",
    "        - LogisticRegression: pos\n",
    "    - \"Feed the dog\"\n",
    "        - LinearSVC: pos\n",
    "        - LogisticRegression: neg\n",
    "    - \"Send report to Kyle\"\n",
    "        - LinearSVC: neg\n",
    "        - LogisticRegression: neg\n",
    "    - \"Send the report to Kyle\"\n",
    "        - LinearSVC: pos\n",
    "        - LogisticRegression: neg\n",
    "\n",
    "Observations:\n",
    "1. LogisticRegression seems _heavily_ biased to be negative.\n",
    "2. LinearSVC seems more fragile when grammar is off (e.g., missing _the_'s) - however, this feels fixable with a more varied/realistic training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier accuracy percent: 89.9458972046889\n",
      "SGDClassifier_classifier accuracy percent: 88.14247069431921\n",
      "LinearSVC_classifier accuracy percent: 89.35978358881876\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(training_set)\n",
    "\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (classify.accuracy(LinearSVC_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LogisticRegression_classifier` and `LinearSVC_classifier` accuracies did not change with another epoch on randomly shuffled training data. `SGDClassifier_classifier` however did (as I suspected it might from my deep learning course).\n",
    "\n",
    "So let's run more epochs with `SGDClassifier_classifier` for now (until I learn if multiple epochs can work with other types of classifiers)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy percent (epoch 1): 87.42110009017132\n",
      "SGDClassifier_classifier accuracy percent (epoch 2): 88.36789900811543\n",
      "SGDClassifier_classifier accuracy percent (epoch 3): 86.02344454463481\n",
      "SGDClassifier_classifier accuracy percent (epoch 4): 89.17944093778178\n",
      "SGDClassifier_classifier accuracy percent (epoch 5): 87.87195671776375\n",
      "SGDClassifier_classifier accuracy percent (epoch 6): 82.95761947700632\n",
      "SGDClassifier_classifier accuracy percent (epoch 7): 80.43282236248874\n",
      "SGDClassifier_classifier accuracy percent (epoch 8): 86.6546438232642\n",
      "SGDClassifier_classifier accuracy percent (epoch 9): 88.50315599639315\n",
      "SGDClassifier_classifier accuracy percent (epoch 10): 88.18755635707845\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for i in range(num_epochs):\n",
    "    random.shuffle(training_set)\n",
    "\n",
    "    SGDClassifier_classifier.train(training_set)\n",
    "    print(f\"SGDClassifier_classifier accuracy percent (epoch {i+1}):\", (classify.accuracy(SGDClassifier_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Informative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/11140887\n",
    "def show_most_informative_features(vectorizer, clf, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Naive Bayes'\")\n",
    "#classifier.show_most_informative_features(15)\n",
    "\n",
    "print(\"Logistic Regressions's\")\n",
    "print('Most Informative Features')\n",
    "show_most_informative_features(LogisticRegression_classifier._vectorizer, LogisticRegression_classifier._clf, 15)\n",
    "\n",
    "print('LinearSVC\\'s')\n",
    "print('Most Informative Features')\n",
    "show_most_informative_features(LinearSVC_classifier._vectorizer, LinearSVC_classifier._clf, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit Learn metrics: Confusion matrix, Classification report, F1 score, Log loss\n",
    "\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** log loss requires `predict_proba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "    \n",
    "# http://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics\n",
    "def f1_macro(predict):\n",
    "    labels, predictions = zip(*predict)\n",
    "    return metrics.f1_score(labels, predictions, average='macro')\n",
    "\n",
    "def classification_report(predict):\n",
    "    labels, predictions = zip(*predict)\n",
    "    return metrics.classification_report(labels, predictions)\n",
    "\n",
    "def confusion_matrix(predict):\n",
    "    labels, predictions = zip(*predict)\n",
    "    print('layout:\\n[[tn   fp]\\n [fn   tp]]\\n')\n",
    "    return metrics.confusion_matrix(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60430846855015252"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro(nb_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.85      0.99      0.91      1823\n",
      "        pos       0.82      0.18      0.29       395\n",
      "\n",
      "avg / total       0.84      0.85      0.80      2218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(nb_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** fix imbalance in training set between neg and pos support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template:\n",
      "[[tn   fp]\n",
      " [fn   tp]]\n",
      "\n",
      "[[1807   16]\n",
      " [ 324   71]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(nb_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'minimum' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\narho_000\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'minimum' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-efc73a2fe3ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-98-8eca78012f4f>\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(predict)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\narho_000\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[0;32m   1633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1634\u001b[0m     \u001b[1;31m# Clipping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1635\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m     \u001b[1;31m# If y_pred is of single dimension, assume y_true to be binary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\narho_000\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mclip\u001b[1;34m(a, a_min, a_max, out)\u001b[0m\n\u001b[0;32m   1705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1706\u001b[0m     \"\"\"\n\u001b[1;32m-> 1707\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'clip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\narho_000\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;31m# a downstream library like 'pandas'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\narho_000\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'minimum' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')"
     ]
    }
   ],
   "source": [
    "log_loss(nb_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next up**: digging into the results (confusion matrix, most informative features), comparing results to LUIS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps and Improvements\n",
    "\n",
    "1. Training set may be too specific/not relevant enough (recipe instructions for positive dataset, recipe descriptions+short movie reviews for negative dataset)\n",
    "2. Throwing features into a blender - need to understand value of each\n",
    "3. Need to review different classifiers, strengths/weaknesses\n",
    "4. Phrase vectorizations of all 0s\n",
    "5. Varying feature vector lengths\n",
    "6. Voting\n",
    "7. Reducing dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things abandoned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I needed a library that supports dependency parsing, which NLTK does not... so I thought I'd add the [Stanford CoreNLP](https://stanfordnlp.github.io/CoreNLP/) toolkit and [its associated software](https://nlp.stanford.edu/software/) to NLTK. However, there are many conflicting instructions for installing the Java-based project, depending on NLTK version used. By the time I figured this out, the installation had become a time sink. So I abandoned this effort in favor of Spacy.io.\n",
    "\n",
    "I might return this way if I want to improve results/implement a voter system between the various linguistic and classification methods later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [s for l in lines for s in sent_tokenize(l)] # punkt\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_sentences = []\n",
    "for s in sentences:\n",
    "    words = word_tokenize(s)\n",
    "    tagged = nltk.pos_tag(words) # averaged_perceptron_tagger\n",
    "    tagged_sentences.append(tagged)\n",
    "print(tagged_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: POS accuracy\n",
    "\n",
    "`Run down to the shop, will you, Peter` is parsed unexpectedly by `nltk.pos_tag`:\n",
    "> `[('Run', 'NNP'), ('down', 'RB'), ('to', 'TO'), ('the', 'DT'), ('shop', 'NN'), (',', ','), ('will', 'MD'), ('you', 'PRP'), (',', ','), ('Peter', 'NNP')]`\n",
    "\n",
    "`Run` is tagged as a `NNP (proper noun, singular)`\n",
    "\n",
    "I expected an output more like what the [Stanford Parser](http://nlp.stanford.edu:8080/parser/) provides:\n",
    "> `Run/VBG down/RP to/TO the/DT shop/NN ,/, will/MD you/PRP ,/, Peter/NNP`\n",
    "\n",
    "`Run` is tagged as a `VGB (verb, gerund/present participle)` - still not quite the `VB` I want, but at least it's a `V*`\n",
    "\n",
    "_MEANWHILE..._\n",
    "\n",
    "`nltk.pos_tag` did better with:\n",
    "> `[('Do', 'VB'), ('not', 'RB'), ('clean', 'VB'), ('soot', 'NN'), ('off', 'IN'), ('the', 'DT'), ('window', 'NN')]`\n",
    "\n",
    "Compared to [Stanford CoreNLP](http://nlp.stanford.edu:8080/corenlp/process) (note that this is different than what [Stanford Parser](http://nlp.stanford.edu:8080/parser/) outputs):\n",
    "> `(ROOT (S (VP (VB Do) (NP (RB not) (JJ clean) (NN soot)) (PP (IN off) (NP (DT the) (NN window))))))`\n",
    "\n",
    "Concern: _clean_ as `VB (verb, base form)` vs `JJ (adjective)` \n",
    "\n",
    "**IMPROVE** POS taggers should vote: nltk.pos_tag (averaged_perceptron_tagger), Stanford Parser, CoreNLP, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note what Spacy POS tagger did with `Run down to the shop, will you Peter`:\n",
    "\n",
    "`Run/VB down/RP to/IN the shop/NN ,/, will/MD you/PRP ,/, Peter/NNP`\n",
    "\n",
    "    where `Run` is the `VB` I expected from POS tagging (compared to `nltk.pos_tag` result of `NNP`). Also note that Spacy collapses `the shop` into a single unit, which should be helpful during featurization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "featuresets = []\n",
    "for ts in tagged_sentences:\n",
    "    s_features = defaultdict(int)\n",
    "    for idx, tup in enumerate(ts):\n",
    "        #print(tup)\n",
    "        pos = tup[1]\n",
    "        # FeatureName.VERB\n",
    "        is_verb = re.match(r'VB.?', pos) is not None\n",
    "        print(tup, is_verb)\n",
    "        if is_verb:\n",
    "            s_features[FeatureName.VERB] += 1\n",
    "            # FOLLOWING_POS\n",
    "            next_idx = idx + 1;\n",
    "            if next_idx < len(ts):\n",
    "                s_features[f'{FeatureName.FOLLOWING}_{ts[next_idx][1]}'] += 1\n",
    "            # VERB_MODIFIER\n",
    "            # VERB_MODIFYING\n",
    "        else:\n",
    "            s_features[FeatureName.VERB] = 0\n",
    "    featuresets.append(dict(s_features))\n",
    "\n",
    "print()\n",
    "print(featuresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Stanford NLP](https://nlp.stanford.edu/software/)\n",
    "Setup guide used: https://stackoverflow.com/a/34112695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get dependency parser, NER, POS tagger\n",
    "!wget https://nlp.stanford.edu/software/stanford-parser-full-2017-06-09.zip\n",
    "!wget https://nlp.stanford.edu/software/stanford-ner-2017-06-09.zip\n",
    "!wget https://nlp.stanford.edu/software/stanford-postagger-full-2017-06-09.zip\n",
    "!unzip stanford-parser-full-2017-06-09.zip\n",
    "!unzip stanford-ner-2017-06-09.zip\n",
    "!unzip stanford-postagger-full-2017-06-09.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "from nltk.parse.stanford import StanfordNeuralDependencyParser\n",
    "from nltk.tag.stanford import StanfordPOSTagger, StanfordNERTagger\n",
    "from nltk.tokenize.stanford import StanfordTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLTK's `SklearnClassifier` wrapper\n",
    "\n",
    "Missing: access to `sklearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Algo accuracy percent: 84.67087466185752\n",
      "MNB_classifier accuracy percent: 87.10550045085664\n",
      "BernoulliNB_classifier accuracy percent: 75.87917042380523\n",
      "LogisticRegression_classifier accuracy percent: 89.9458972046889\n",
      "SGDClassifier_classifier accuracy percent: 88.14247069431921\n",
      "SVC_classifier accuracy percent: 87.91704238052299\n",
      "LinearSVC_classifier accuracy percent: 89.404869251578\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "# http://scikit-learn.org/stable/modules/linear_model.html\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "# http://scikit-learn.org/stable/modules/svm.html#svm-classification\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.train(training_set)\n",
    "print(\"MultinomialNB classifier accuracy percent:\", (classify.accuracy(mnb, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(training_set)\n",
    "print(\"SVC_classifier accuracy percent:\", (classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (classify.accuracy(LinearSVC_classifier, testing_set))*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
